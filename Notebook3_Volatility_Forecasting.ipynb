{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GIJOE1003/3103ETF/blob/main/Notebook3_Volatility_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b34729b",
      "metadata": {
        "id": "7b34729b"
      },
      "source": [
        "# ETF Volatility Forecasting\n",
        "\n",
        "This notebook forecasts 7-day volatility using multiple regression models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "53cbbc13",
      "metadata": {
        "id": "53cbbc13"
      },
      "outputs": [],
      "source": [
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e14f6af",
      "metadata": {
        "id": "8e14f6af"
      },
      "source": [
        "## Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "56729974",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56729974",
        "outputId": "12d28084-2824-437c-9bdb-9517098887a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  10 of 10 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined data saved: (25160, 7)\n",
            "        Date Ticker   Open  Close   High    Low    Volume\n",
            "0 2015-04-10    EEM  34.21  34.38  34.39  34.18  49899000\n",
            "1 2015-04-13    EEM  34.45  34.18  34.57  34.17  55031100\n",
            "2 2015-04-14    EEM  34.26  34.34  34.41  34.11  42601100\n",
            "3 2015-04-15    EEM  34.33  34.58  34.59  34.26  40254700\n",
            "4 2015-04-16    EEM  34.67  34.85  35.05  34.62  55057700\n",
            "            Date Ticker    Open   Close    High     Low    Volume\n",
            "25155 2025-04-03    XLV  143.76  143.13  145.19  143.05  10990600\n",
            "25156 2025-04-04    XLV  141.14  135.28  141.71  135.23  21341100\n",
            "25157 2025-04-07    XLV  131.71  134.47  137.37  129.66  29940300\n",
            "25158 2025-04-08    XLV  139.43  132.98  139.44  131.28  20860400\n",
            "25159 2025-04-09    XLV  130.13  138.76  139.24  129.68  39441700\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25160 entries, 0 to 25159\n",
            "Data columns (total 7 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   Date    25160 non-null  datetime64[ns]\n",
            " 1   Ticker  25160 non-null  object        \n",
            " 2   Open    25160 non-null  float64       \n",
            " 3   Close   25160 non-null  float64       \n",
            " 4   High    25160 non-null  float64       \n",
            " 5   Low     25160 non-null  float64       \n",
            " 6   Volume  25160 non-null  int64         \n",
            "dtypes: datetime64[ns](1), float64(4), int64(1), object(1)\n",
            "memory usage: 1.3+ MB\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Data Collection\n",
        "tickers = ['SPY', 'QQQ', 'GLD','TLT', 'VTI','EEM','XLF','XLV','VEA','VNQ']\n",
        "end_date = pd.to_datetime('today')\n",
        "start_date = end_date - pd.DateOffset(months=120)\n",
        "\n",
        "# Download prices\n",
        "df_raw = yf.download(tickers, start=start_date, end=end_date)\n",
        "\n",
        "df_open = df_raw['Open'].reset_index().melt(id_vars='Date', var_name='Ticker', value_name='Open')\n",
        "df_close = df_raw['Close'].reset_index().melt(id_vars='Date', var_name='Ticker', value_name='Close')\n",
        "df_high  = df_raw['High'].reset_index().melt(id_vars='Date', var_name='Ticker', value_name='High')\n",
        "df_low   = df_raw['Low'].reset_index().melt(id_vars='Date', var_name='Ticker', value_name='Low')\n",
        "df_volume = df_raw['Volume'].reset_index().melt(id_vars='Date', var_name='Ticker', value_name='Volume')\n",
        "\n",
        "# Merge into one DataFrame\n",
        "df = df_open.merge(df_close, on=['Date', 'Ticker']).merge(df_high, on=['Date', 'Ticker']).merge(df_low, on=['Date', 'Ticker']).merge(df_volume, on=['Date', 'Ticker'])\n",
        "df = df.round(2)\n",
        "\n",
        "# Create CSV File\n",
        "df.to_csv(\"combined_etf_data.csv\", index = False)\n",
        "print(f\"Combined data saved: {df.shape}\")\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "\n",
        "df.isnull().sum()\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09524b1c",
      "metadata": {
        "id": "09524b1c"
      },
      "source": [
        "## Feature Engineering and Volatility Target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Return'] = df.groupby('Ticker')['Close'].pct_change().round(4)\n",
        "df['Return'] = df['Return'].fillna(0.0)\n",
        "df['Volatility7'] = df.groupby('Ticker')['Return'].rolling(window=20).std().reset_index(level=0, drop=True).round(4)\n",
        "df['Volatility7'] = df['Volatility7'].fillna(0.0)\n",
        "\n",
        "\n",
        "df['MA5'] = df.groupby('Ticker')['Close'].transform(lambda x: x.rolling(20).mean()).round(4)\n",
        "df['Close_MA5_diff'] = ((df['Close'] - df['MA5']) / df['MA5'] * 100).round(4)\n",
        "\n",
        "windows = [20, 50, 200]\n",
        "for w in windows:\n",
        "    df[f'SMA{w}'] = df.groupby('Ticker')['Close'].transform(lambda x: x.rolling(w).mean()).round(4)\n",
        "    df[f'EMA{w}'] = df.groupby('Ticker')['Close'].transform(lambda x: x.ewm(span=w, adjust=False).mean()).round(4)\n",
        "\n",
        "\n",
        "df['PrevClose'] = df.groupby('Ticker')['Close'].shift(1)\n",
        "df['TR'] = df[['High', 'Low', 'PrevClose']].apply(lambda x: max(x[0]-x[1], abs(x[0]-x[2]), abs(x[1]-x[2])), axis=1).round(4)\n",
        "df['ATR7'] = df.groupby('Ticker')['TR'].transform(lambda x: x.rolling(7).mean()).round(4)\n",
        "df['ATR7_pct'] = (df['ATR7'] / df['Close'] * 100).round(4)\n",
        "\n",
        "def compute_rsi(series, window=14):\n",
        "    delta = series.diff()\n",
        "    gain = delta.where(delta > 0, 0)\n",
        "    loss = -delta.where(delta < 0, 0)\n",
        "\n",
        "    avg_gain = gain.rolling(window=window).mean()\n",
        "    avg_loss = loss.rolling(window=window).mean()\n",
        "\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "df['RSI14'] = df.groupby('Ticker')['Close'].transform(compute_rsi)\n",
        "\n",
        "ema_12 = df.groupby('Ticker')['Close'].transform(lambda x: x.ewm(span=12, adjust=False).mean())\n",
        "ema_26 = df.groupby('Ticker')['Close'].transform(lambda x: x.ewm(span=26, adjust=False).mean())\n",
        "\n",
        "df['MACD'] = (ema_12 - ema_26).round(4)\n",
        "df['Signal_Line'] = df.groupby('Ticker')['MACD'].transform(lambda x: x.ewm(span=9, adjust=False).mean()).round(4)\n",
        "\n",
        "low14 = df.groupby('Ticker')['Low'].transform(lambda x: x.rolling(14).min())\n",
        "high14 = df.groupby('Ticker')['High'].transform(lambda x: x.rolling(14).max())\n",
        "\n",
        "df['%K'] = ((df['Close'] - low14) / (high14 - low14) * 100).round(2)\n",
        "df['%D'] = df.groupby('Ticker')['%K'].transform(lambda x: x.rolling(3).mean())\n",
        "\n",
        "df['DayOfWeek'] = pd.to_datetime(df['Date']).dt.dayofweek\n",
        "df['Month'] = pd.to_datetime(df['Date']).dt.month\n",
        "df['IsMonthEnd'] = pd.to_datetime(df['Date']).dt.is_month_end.astype(int)\n",
        "\n",
        "\n",
        "df.to_csv(\"combined_etf_data_features.csv\", index = False)\n",
        "print(f\"Combined data saved: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vpzvjBvUsR5",
        "outputId": "78be57ba-cf2d-4e32-f3c4-213c954fba5c"
      },
      "id": "7vpzvjBvUsR5",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-c7f3bfe94bce>:17: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  df['TR'] = df[['High', 'Low', 'PrevClose']].apply(lambda x: max(x[0]-x[1], abs(x[0]-x[2]), abs(x[1]-x[2])), axis=1).round(4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined data saved: (25160, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "91d4fa78",
      "metadata": {
        "id": "91d4fa78"
      },
      "outputs": [],
      "source": [
        "df['Return'] = df.groupby('Ticker')['Close'].pct_change()\n",
        "df['Rolling_Std_7'] = df.groupby('Ticker')['Close'].transform(lambda x: x.rolling(7).std().shift(-7))\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "features = ['High', 'Low', 'Volume','Return',\n",
        "    'MA5', 'Close_MA5_diff', 'SMA20', 'EMA20','Volatility7',\n",
        "    'SMA50', 'EMA50', 'SMA200', 'EMA200', 'TR', 'ATR7','RSI14','MACD','Signal_Line','%K','%D','DayOfWeek','Month','IsMonthEnd']\n",
        "X = df[features]\n",
        "y = df['Rolling_Std_7']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32fcd780",
      "metadata": {
        "id": "32fcd780"
      },
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "40645f79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40645f79",
        "outputId": "66c827c5-e9e5-4973-e71b-ec9f051e7482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression - RMSE: 0.4151, MAE: 0.2772, R2: 0.5020\n"
          ]
        }
      ],
      "source": [
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
        "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
        "r2_lr = r2_score(y_test, y_pred_lr)\n",
        "print(f\"Linear Regression - RMSE: {rmse_lr:.4f}, MAE: {mae_lr:.4f}, R2: {r2_lr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26548c68",
      "metadata": {
        "id": "26548c68"
      },
      "source": [
        "### Random Forest Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d68b8100",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d68b8100",
        "outputId": "c1105907-aeaa-4fb1-b39f-f0afafb3bf74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - RMSE: 0.4400, MAE: 0.3147, R2: 0.4406\n"
          ]
        }
      ],
      "source": [
        "\n",
        "rf = RandomForestRegressor()\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "print(f\"Random Forest - RMSE: {rmse_rf:.4f}, MAE: {mae_rf:.4f}, R2: {r2_rf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cabf07d",
      "metadata": {
        "id": "2cabf07d"
      },
      "source": [
        "### XGBoost Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "00c5dc05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00c5dc05",
        "outputId": "2fba4324-1897-4b00-9848-1299edbbdb3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost - RMSE: 0.4172, MAE: 0.2937, R2: 0.4722\n"
          ]
        }
      ],
      "source": [
        "\n",
        "xgb = XGBRegressor()\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
        "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "print(f\"XGBoost - RMSE: {rmse_xgb:.4f}, MAE: {mae_xgb:.4f}, R2: {r2_xgb:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f7cda6a",
      "metadata": {
        "id": "7f7cda6a"
      },
      "source": [
        "### LSTM Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9fc3e201",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fc3e201",
        "outputId": "f9b3f990-4647-48d3-a1d1-f27a02197e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 4.7552 - val_loss: 1.9368\n",
            "Epoch 2/10\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 3.5547 - val_loss: 1.9712\n",
            "Epoch 3/10\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 3.5515 - val_loss: 1.9209\n",
            "Epoch 4/10\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 3.4979 - val_loss: 2.0200\n",
            "Epoch 5/10\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 3.5720 - val_loss: 1.9601\n",
            "Epoch 6/10\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 3.5151 - val_loss: 2.0539\n",
            "Epoch 7/10\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 3.6992 - val_loss: 2.0341\n",
            "Epoch 8/10\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 3.5192 - val_loss: 1.8986\n",
            "Epoch 9/10\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 3.6155 - val_loss: 1.9973\n",
            "Epoch 10/10\n",
            "\u001b[1m515/515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 3.5915 - val_loss: 1.9243\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "LSTM - RMSE: 1.1209, MAE: 1.0426, R2: -2.7924\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Rebuild sequence data for LSTM\n",
        "def create_lstm_sequences(data, target, lookback=7):\n",
        "    X_lstm, y_lstm = [], []\n",
        "    for ticker in data['Ticker'].unique():\n",
        "        df_ticker = data[data['Ticker'] == ticker].reset_index(drop=True)\n",
        "        for i in range(lookback, len(df_ticker) - 7):\n",
        "            X_lstm.append(df_ticker[features].iloc[i-lookback:i].values)\n",
        "            y_lstm.append(df_ticker[target].iloc[i])\n",
        "    return np.array(X_lstm), np.array(y_lstm)\n",
        "\n",
        "X_lstm, y_lstm = create_lstm_sequences(df, 'Rolling_Std_7')\n",
        "X_train_lstm, X_test_lstm = X_lstm[:int(0.8*len(X_lstm))], X_lstm[int(0.8*len(X_lstm)):]\n",
        "y_train_lstm, y_test_lstm = y_lstm[:int(0.8*len(y_lstm))], y_lstm[int(0.8*len(y_lstm)):]\n",
        "\n",
        "lstm_model = Sequential([\n",
        "    LSTM(64, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm_model.compile(optimizer='adam', loss='mse')\n",
        "early_stop = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "lstm_model.fit(X_train_lstm, y_train_lstm, epochs=10, batch_size=32, validation_split=0.1, callbacks=[early_stop])\n",
        "y_pred_lstm = lstm_model.predict(X_test_lstm)\n",
        "\n",
        "rmse_lstm = np.sqrt(mean_squared_error(y_test_lstm, y_pred_lstm))\n",
        "mae_lstm = mean_absolute_error(y_test_lstm, y_pred_lstm)\n",
        "r2_lstm = r2_score(y_test_lstm, y_pred_lstm)\n",
        "print(f\"LSTM - RMSE: {rmse_lstm:.4f}, MAE: {mae_lstm:.4f}, R2: {r2_lstm:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Train models\n",
        "lr_model = LinearRegression().fit(X_train, y_train)\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42).fit(X_train, y_train)\n",
        "xgb_model = XGBRegressor(n_estimators=100, random_state=42).fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Simple average ensemble\n",
        "y_pred_ensemble = (y_pred_lr + y_pred_rf + y_pred_xgb) / 3\n",
        "\n",
        "# Evaluate\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred_ensemble))\n",
        "mae = mean_absolute_error(y_test, y_pred_ensemble)\n",
        "r2 = r2_score(y_test, y_pred_ensemble)\n",
        "\n",
        "print(f\"Ensemble Volatility Forecasting\")\n",
        "print(f\"RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p9gm_7OWO2F",
        "outputId": "c12d25cd-e469-44de-c4a9-ad8ec3b38863"
      },
      "id": "1p9gm_7OWO2F",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Ensemble Volatility Forecasting\n",
            "✅ RMSE: 0.3897, MAE: 0.2761, R²: 0.5394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51a2f694",
      "metadata": {
        "id": "51a2f694"
      },
      "source": [
        "## Final Comparison & Best Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5d114351",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d114351",
        "outputId": "2032114f-dd0e-4cb1-fab1-9d0bceebd881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       RMSE       MAE        R2\n",
            "Ensemble           0.389702  0.276082  0.539414\n",
            "Linear Regression  0.415144  0.277158  0.501959\n",
            "XGBoost            0.417188  0.293726  0.472153\n",
            "Random Forest      0.439976  0.314665  0.440596\n",
            "LSTM               1.120897  1.042584 -2.792351\n"
          ]
        }
      ],
      "source": [
        "\n",
        "results = {\n",
        "    'Linear Regression': (rmse_lr, mae_lr, r2_lr),\n",
        "    'Random Forest': (rmse_rf, mae_rf, r2_rf),\n",
        "    'XGBoost': (rmse_xgb, mae_xgb, r2_xgb),\n",
        "    'LSTM': (rmse_lstm, mae_lstm, r2_lstm),\n",
        "    'Ensemble': (rmse, mae, r2)\n",
        "}\n",
        "\n",
        "df_results = pd.DataFrame(results, index=['RMSE', 'MAE', 'R2']).T.sort_values(by='RMSE')\n",
        "print(df_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbk7kgknZlHu"
      },
      "id": "pbk7kgknZlHu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step before training\n",
        "df['Rolling_STD_7'] = (\n",
        "    df.sort_values(['Ticker', 'Date'])\n",
        "      .groupby('Ticker')['Return']\n",
        "      .rolling(window=7)\n",
        "      .std()\n",
        "      .shift(-7)\n",
        "      .reset_index(level=0, drop=True)\n",
        ")\n",
        "\n",
        "#\n",
        "forecast_days = 7\n",
        "today = datetime.today().date()\n",
        "\n",
        "# Generate next 7 days\n",
        "future_dates = []\n",
        "while len(future_dates) < forecast_days:\n",
        "    today+= timedelta(days=1)\n",
        "    if today.weekday() < 5:  # Mon–Fri\n",
        "        future_dates.append(today)\n",
        "\n",
        "# Prepare latest data\n",
        "latest_df = df.groupby(\"Ticker\").tail(1).copy().reset_index(drop=True)\n",
        "future_df = pd.DataFrame(np.repeat(latest_df.values, forecast_days, axis=0), columns=latest_df.columns)\n",
        "future_df[\"Date\"] = future_dates * len(latest_df)\n",
        "\n",
        "\n",
        "for col in features:\n",
        "    if pd.api.types.is_numeric_dtype(future_df[col]):\n",
        "        std_dev = future_df[col].std()\n",
        "        if std_dev > 0:\n",
        "            future_df[col] += np.random.normal(0, 0.01 * std_dev, size=len(future_df))\n",
        "\n",
        "\n",
        "\n",
        "# Features\n",
        "features = ['High', 'Low', 'Return', 'Volume',\n",
        "    'MA5', 'Close_MA5_diff', 'SMA20', 'EMA20', 'Volatility7',\n",
        "    'SMA50', 'EMA50', 'SMA200', 'EMA200', 'TR', 'ATR7',\n",
        "    'RSI14', 'MACD', 'Signal_Line', '%K', '%D',\n",
        "    'DayOfWeek', 'Month', 'IsMonthEnd']\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_full = scaler.fit_transform(df[features])\n",
        "X_future = scaler.transform(future_df[features])\n",
        "\n",
        "X_future += np.random.normal(0, 0.01, X_future.shape)\n",
        "\n",
        "# Train base models\n",
        "y = df['Rolling_STD_7']  # Your volatility target\n",
        "\n",
        "\n",
        "# Filter rows where target is not NaN\n",
        "valid_rows = ~y.isna()\n",
        "X_full_clean = X_full[valid_rows]\n",
        "y_clean = y[valid_rows]\n",
        "\n",
        "model_lr = LinearRegression().fit(X_full_clean, y_clean)\n",
        "model_rf = RandomForestRegressor(n_estimators=100, random_state=42).fit(X_full_clean, y_clean)\n",
        "model_xgb = XGBRegressor(n_estimators=100, random_state=42).fit(X_full_clean, y_clean)\n",
        "\n",
        "\n",
        "# Predict\n",
        "pred_lr = model_lr.predict(X_future)\n",
        "pred_rf = model_rf.predict(X_future)\n",
        "pred_xgb = model_xgb.predict(X_future)\n",
        "\n",
        "# Simple average ensemble\n",
        "future_df['Predicted_Volatility'] = (pred_lr + pred_rf + pred_xgb) / 3\n",
        "\n",
        "# Output result\n",
        "final_output = future_df[['Ticker', 'Date', 'Predicted_Volatility']]\n",
        "print(final_output)\n",
        "\n",
        "# Optionally export\n",
        "final_output.to_csv(\"volatility.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "u9mAWpUaXDvd"
      },
      "id": "u9mAWpUaXDvd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}